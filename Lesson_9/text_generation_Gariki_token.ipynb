{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUadMsBKO9su"
   },
   "source": [
    "# Задание\n",
    "\n",
    "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9ACpsCaUGTpN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-iABhnZndL0",
    "outputId": "86259291-2660-4aff-9ed9-7f1a1d70f3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "gdrive\tsample_data\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8qRAU8c_uRd",
    "outputId": "4930e8dc-4a58-491c-c958-76bd1c360e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'gdrive/My Drive/work/GB_NLP/9_2'\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd gdrive/My\\ Drive/work/GB_NLP/9_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBp_TkcnAEij",
    "outputId": "a4e5add5-4072-42ee-887c-ebbbc1035fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взял для обучения четверостишья Губермана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSugx2v9GfFB",
    "outputId": "751ea45e-b70a-4f1f-a2c7-9f3b62a83484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-28 14:16:39--  https://raw.githubusercontent.com/drafterleo/pie-poem/master/data/gariki.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 688530 (672K) [text/plain]\n",
      "Saving to: ‘gariki.txt’\n",
      "\n",
      "gariki.txt          100%[===================>] 672.39K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2022-06-28 14:16:40 (24.9 MB/s) - ‘gariki.txt’ saved [688530/688530]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/drafterleo/pie-poem/master/data/gariki.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-y2V7wzbVXe",
    "outputId": "3bf4afbb-f60d-4d54-be3d-ff8ae99d1853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gariki.txt\n"
     ]
    }
   ],
   "source": [
    "!ls *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-an5tHuaRmqD"
   },
   "outputs": [],
   "source": [
    "path_to_file = 'gariki.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aavnuByVymwK",
    "outputId": "2d751059-7477-4e02-c75f-e632d2738b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 386661 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Duhg9NrUymwO",
    "outputId": "fbf98689-dc03-4f0b-abcb-05522613b6d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Утучняется плоть,\n",
      "Испаряется пыл.\n",
      "Годы вышли на медленный ужин. \n",
      "И приятно подумать, \n",
      "Что все-таки был \n",
      "И кому-то бывал я нужен.\n",
      "\n",
      "Мне Маркса жаль: его наследство\n",
      "свалилось в русскую купель:\n",
      "здесь цель оправдывала средства, и \n",
      "средства обосрали цель.\n",
      "\n",
      "Во благо классу-гегемону, \n",
      "чтоб неослабно правил он,\n",
      "во всякий миг доступен шмону \n",
      "отдельно взятый гегемон.\n",
      "\n",
      "Слой человека в нас чуть-чуть \n",
      "наслоен зыбко и тревожно,\n",
      "легко в скотину нас вернуть, \n",
      "поднять обратно очень сложно.\n",
      "\n",
      "Я молодых, в остатках \n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_zyJ7A0tGTp6",
    "outputId": "8c30a9bf-ae36-48d8-d834-7919999371da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0869c393-a4fe-4147-968e-24eb638231ec\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Утучняется плоть,\\nИспаряется пыл.\\nГоды вышли...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Мне Маркса жаль: его наследство\\nсвалилось в р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Во благо классу-гегемону, \\nчтоб неослабно пра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Слой человека в нас чуть-чуть \\nнаслоен зыбко ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Я молодых, в остатках сопель, \\nбоюсь, трясущи...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0869c393-a4fe-4147-968e-24eb638231ec')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0869c393-a4fe-4147-968e-24eb638231ec button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0869c393-a4fe-4147-968e-24eb638231ec');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Утучняется плоть,\\nИспаряется пыл.\\nГоды вышли...\n",
       "1  Мне Маркса жаль: его наследство\\nсвалилось в р...\n",
       "2  Во благо классу-гегемону, \\nчтоб неослабно пра...\n",
       "3  Слой человека в нас чуть-чуть \\nнаслоен зыбко ...\n",
       "4  Я молодых, в остатках сопель, \\nбоюсь, трясущи..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(text.split(sep='\\n\\n'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jGJ53ly7GTp8",
    "outputId": "73197199-da41-4e40-89eb-e6f928013785"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b36956f1-a211-414c-b415-062a0a42f9fa\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gariki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Утучняется плоть,\\nИспаряется пыл.\\nГоды вышли...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Мне Маркса жаль: его наследство\\nсвалилось в р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Во благо классу-гегемону, \\nчтоб неослабно пра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Слой человека в нас чуть-чуть \\nнаслоен зыбко ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Я молодых, в остатках сопель, \\nбоюсь, трясущи...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b36956f1-a211-414c-b415-062a0a42f9fa')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b36956f1-a211-414c-b415-062a0a42f9fa button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b36956f1-a211-414c-b415-062a0a42f9fa');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              gariki\n",
       "0  Утучняется плоть,\\nИспаряется пыл.\\nГоды вышли...\n",
       "1  Мне Маркса жаль: его наследство\\nсвалилось в р...\n",
       "2  Во благо классу-гегемону, \\nчтоб неослабно пра...\n",
       "3  Слой человека в нас чуть-чуть \\nнаслоен зыбко ...\n",
       "4  Я молодых, в остатках сопель, \\nбоюсь, трясущи..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={0: 'gariki'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OPaAQz2zGTp9"
   },
   "outputs": [],
   "source": [
    "def replacement_punkt(text, regex = re.compile(r'[^\\w\\s]')):\n",
    "    try:\n",
    "        return re.sub(regex, \" \", text)\n",
    "    except:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iJZGIelyGTp-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def replacement(text, regex=re.compile('\\\\n')):\n",
    "    try:\n",
    "        return re.sub(regex, \" \\n \", text)\n",
    "    except:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробовал обозначать начало и конец четверостишья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "m0y-dkq5GTp_"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = '<start> ' + text + ' <end>'\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "f4aFPqpTGTqA"
   },
   "outputs": [],
   "source": [
    "df['gariki_next'] = df['gariki'].apply(replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "W_ruR_CJGTqB"
   },
   "outputs": [],
   "source": [
    "df['gariki_next'] = df['gariki_next'].apply(replacement_punkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VMv7wR7IGTqD"
   },
   "outputs": [],
   "source": [
    "df['gariki_next'] = df['gariki_next'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "XakZxF8yGTqD",
    "outputId": "63c98ffe-6a52-4fdd-c4bf-8f3328098176"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> утучняется плоть  \\n испаряется пыл  \\n годы вышли на медленный ужин   \\n и приятно подумать   \\n что все таки был  \\n и кому то бывал я нужен  <end>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gariki_next'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "Uc1uPmLDGTqD",
    "outputId": "28e90d99-3173-4376-d8d1-5e6516005bda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-30a89a7d-f80d-4e8b-b75e-ad5b2c62a73b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gariki</th>\n",
       "      <th>gariki_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Утучняется плоть,\\nИспаряется пыл.\\nГоды вышли...</td>\n",
       "      <td>&lt;start&gt; утучняется плоть  \\n испаряется пыл  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Мне Маркса жаль: его наследство\\nсвалилось в р...</td>\n",
       "      <td>&lt;start&gt; мне маркса жаль  его наследство \\n сва...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Во благо классу-гегемону, \\nчтоб неослабно пра...</td>\n",
       "      <td>&lt;start&gt; во благо классу гегемону   \\n чтоб нео...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Слой человека в нас чуть-чуть \\nнаслоен зыбко ...</td>\n",
       "      <td>&lt;start&gt; слой человека в нас чуть чуть  \\n насл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Я молодых, в остатках сопель, \\nбоюсь, трясущи...</td>\n",
       "      <td>&lt;start&gt; я молодых  в остатках сопель   \\n боюс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30a89a7d-f80d-4e8b-b75e-ad5b2c62a73b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-30a89a7d-f80d-4e8b-b75e-ad5b2c62a73b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-30a89a7d-f80d-4e8b-b75e-ad5b2c62a73b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              gariki  \\\n",
       "0  Утучняется плоть,\\nИспаряется пыл.\\nГоды вышли...   \n",
       "1  Мне Маркса жаль: его наследство\\nсвалилось в р...   \n",
       "2  Во благо классу-гегемону, \\nчтоб неослабно пра...   \n",
       "3  Слой человека в нас чуть-чуть \\nнаслоен зыбко ...   \n",
       "4  Я молодых, в остатках сопель, \\nбоюсь, трясущи...   \n",
       "\n",
       "                                         gariki_next  \n",
       "0  <start> утучняется плоть  \\n испаряется пыл  \\...  \n",
       "1  <start> мне маркса жаль  его наследство \\n сва...  \n",
       "2  <start> во благо классу гегемону   \\n чтоб нео...  \n",
       "3  <start> слой человека в нас чуть чуть  \\n насл...  \n",
       "4  <start> я молодых  в остатках сопель   \\n боюс...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koG73_tbGTqE",
    "outputId": "0e970e7d-5efb-4c5c-b1ee-ca02af6789d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3322"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['gariki_next'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo61xRdCGTqF",
    "outputId": "6e209096-fe86-474d-f7b5-f82ce2c7fe6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>',\n",
       " 'утучняется',\n",
       " 'плоть',\n",
       " 'испаряется',\n",
       " 'пыл',\n",
       " 'годы',\n",
       " 'вышли',\n",
       " 'на',\n",
       " 'медленный',\n",
       " 'ужин',\n",
       " 'и',\n",
       " 'приятно',\n",
       " 'подумать',\n",
       " 'что',\n",
       " 'все',\n",
       " 'таки',\n",
       " 'был',\n",
       " 'и',\n",
       " 'кому',\n",
       " 'то',\n",
       " 'бывал',\n",
       " 'я',\n",
       " 'нужен',\n",
       " '<end>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gariki_next'][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "28VMxJ6_GTqG"
   },
   "outputs": [],
   "source": [
    "list_for_vocab = []\n",
    "for i in range(len(df['gariki_next'])):\n",
    "    for token in df['gariki_next'][i].split():\n",
    "        list_for_vocab.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "iKoGh5RxGTqH"
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(list_for_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g54oK_KlGTqI",
    "outputId": "4f66ade7-3920-40da-97ea-23696aec8b44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19137"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "token2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2token = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "igHoq8niGTqJ"
   },
   "outputs": [],
   "source": [
    "text_as_int = np.array([token2idx[c] for c in list_for_vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-DhY8bbTY3g",
    "outputId": "e80b9108-5dde-41ae-97fe-c9ec260e9bab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    3, 17811, 10953,  5528, 13065,  2773,  2481,  7976,  7275,\n",
       "        17349,  5181, 12541, 11296, 18644,  2131, 16345,  1060,  5181,\n",
       "         6121, 16674,  1050, 19045,  9215,     2,     3,  7550,  7200,\n",
       "         4128,  4016,  8314, 14140,  1098, 13986,  6552,  4964, 18387,\n",
       "         9857, 15649,  5181, 15649,  9421, 18387,     2,     3,  1720,\n",
       "          590,  5924,  2567, 18645,  8791]),\n",
       " ['<start>',\n",
       "  'утучняется',\n",
       "  'плоть',\n",
       "  'испаряется',\n",
       "  'пыл',\n",
       "  'годы',\n",
       "  'вышли',\n",
       "  'на',\n",
       "  'медленный',\n",
       "  'ужин',\n",
       "  'и',\n",
       "  'приятно',\n",
       "  'подумать',\n",
       "  'что',\n",
       "  'все',\n",
       "  'таки',\n",
       "  'был',\n",
       "  'и',\n",
       "  'кому',\n",
       "  'то',\n",
       "  'бывал',\n",
       "  'я',\n",
       "  'нужен',\n",
       "  '<end>',\n",
       "  '<start>',\n",
       "  'мне',\n",
       "  'маркса',\n",
       "  'жаль',\n",
       "  'его',\n",
       "  'наследство',\n",
       "  'свалилось',\n",
       "  'в',\n",
       "  'русскую',\n",
       "  'купель',\n",
       "  'здесь',\n",
       "  'цель',\n",
       "  'оправдывала',\n",
       "  'средства',\n",
       "  'и',\n",
       "  'средства',\n",
       "  'обосрали',\n",
       "  'цель',\n",
       "  '<end>',\n",
       "  '<start>',\n",
       "  'во',\n",
       "  'благо',\n",
       "  'классу',\n",
       "  'гегемону',\n",
       "  'чтоб',\n",
       "  'неослабно'],\n",
       " 68634,\n",
       " 68634)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int[:50], list_for_vocab[:50], len(text_as_int), len(list_for_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### train and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wZyHhhKjGTqL"
   },
   "outputs": [],
   "source": [
    "seq_list = []\n",
    "for i in range(len(df['gariki_next'])):\n",
    "    seq_list.append(len(df['gariki_next'][i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9PqE1i2GTqM",
    "outputId": "519a1554-ae6f-4d27-daee-0c726a049649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3IdPG53GTqM",
    "outputId": "241c4c35-58af-4904-81d0-e6b85133bdbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gonhO881GTqN",
    "outputId": "b1326702-a201-4390-c38d-92f537232844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.66044551475015"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(seq_list)/len(seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UHJDA39zf-O",
    "outputId": "b51f1515-dc1f-482a-ff61-e207fe9e5366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "утучняется\n",
      "плоть\n",
      "испаряется\n",
      "пыл\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 40\n",
    "examples_per_epoch = len(text_as_int)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "token_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in token_dataset.take(5):\n",
    "    print(idx2token[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4hkDU3i7ozi",
    "outputId": "b2f94b6d-766c-4193-edf2-64de1b52835b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<start> утучняется плоть испаряется пыл годы вышли на медленный ужин и приятно подумать что все таки был и кому то бывал я нужен <end> <start> мне маркса жаль его наследство свалилось в русскую купель здесь цель оправдывала средства и средства обосрали'\n",
      "'цель <end> <start> во благо классу гегемону чтоб неослабно правил он во всякий миг доступен шмону отдельно взятый гегемон <end> <start> слой человека в нас чуть чуть наслоен зыбко и тревожно легко в скотину нас вернуть поднять обратно очень сложно <end>'\n",
      "'<start> я молодых в остатках сопель боюсь трясущих жизнь как грушу в душе темно у них как в жопе а в жопе зуд потешить душу <end> <start> когда истории сквозняк свистит по душам и державам один ползет в нору слизняк другой'\n",
      "'вздувается удавом <end> <start> добро не отвергая средства зла по ним и пожинает результаты в раю где применяется смола архангелы копытны и рогаты <end> <start> по крови проникая до корней пронизывая воздух небосвода неволя растлевает нас сильней чем самая беспутная свобода'\n",
      "'<end> <start> перо и глаз держа в союзе я не напрасно хлеб свой ем россия гордиев санузел острейших нынешних проблем <end> <start> мне повезло я знал страну одну единственную в мире в своем же собственном плену в своей живущую квартире <end>'\n"
     ]
    }
   ],
   "source": [
    "sequences = token_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(' '.join(idx2token[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiCopyGZymwi"
   },
   "source": [
    "Print the first example input and target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNbw-iR0ymwj",
    "outputId": "357432a1-1751-4a38-9ba4-e510feef5988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '<start> утучняется плоть испаряется пыл годы вышли на медленный ужин и приятно подумать что все таки был и кому то бывал я нужен <end> <start> мне маркса жаль его наследство свалилось в русскую купель здесь цель оправдывала средства и средства'\n",
      "Target data: 'утучняется плоть испаряется пыл годы вышли на медленный ужин и приятно подумать что все таки был и кому то бывал я нужен <end> <start> мне маркса жаль его наследство свалилось в русскую купель здесь цель оправдывала средства и средства обосрали'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(' '.join(idx2token[input_example.numpy()])))\n",
    "    print('Target data:', repr(' '.join(idx2token[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2pGotuNzf-S",
    "outputId": "62756426-6d6a-4d4f-df17-1068f6b2e51b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 40), dtype=tf.int64, name=None), TensorSpec(shape=(64, 40), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 3000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE, seed=21).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 2048\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ZUzZLkyC1UpP"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tm1u0iNSaLOi"
   },
   "outputs": [],
   "source": [
    "class RNNgenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, batch_size):\n",
    "        super(RNNgenerator, self).__init__()\n",
    "        \n",
    "        self.emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "                                 \n",
    "        self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform')\n",
    "        self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform')\n",
    "                           \n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        emb_x = self.emb(x)\n",
    "        x1 = self.gru1(emb_x)\n",
    "        x = x1\n",
    "        for _ in range(3):\n",
    "            x = self.gru2(x)\n",
    "        #x = self.gru1(x)\n",
    "        x = (x + x1)/2\n",
    "        return self.fc(x)\n",
    "\n",
    "model = RNNgenerator(vocab_size, embedding_dim, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "FNfDlxWZ8NXK"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "                                 \n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-_70kKAPrPU",
    "outputId": "6f47c582-96b4-43b0-923f-53560bd24c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40, 19137) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPGmAAXmVLGC",
    "outputId": "b01a3866-ef30-48e8-80e8-6a8c55ac0640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 2048)        39192576  \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, None, 4096)        75522048  \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, None, 4096)        100687872 \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, None, 4096)        100687872 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 19137)       78404289  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 394,494,657\n",
      "Trainable params: 394,494,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFkC1pcZjQFq",
    "outputId": "2fc3df02-93de-4812-a25d-68de2961ffc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40, 19137), dtype=float32, numpy=\n",
       "array([[-2.8247799e-04,  5.8257574e-04, -4.1446462e-04, ...,\n",
       "        -8.4931822e-04, -1.9034298e-04,  3.7484785e-04],\n",
       "       [-5.8326131e-04,  1.4189158e-03, -2.2854861e-04, ...,\n",
       "        -1.8075497e-03,  5.0783140e-04,  6.8543729e-04],\n",
       "       [-7.0876552e-04,  1.0629648e-03,  3.0784251e-04, ...,\n",
       "        -1.5513515e-03,  1.1262735e-03,  9.6897804e-04],\n",
       "       ...,\n",
       "       [ 4.9388484e-04, -4.3567090e-04, -2.1847798e-03, ...,\n",
       "        -1.4940186e-03, -4.0068091e-03, -1.6869081e-03],\n",
       "       [ 3.4510085e-05, -8.6202373e-04, -2.7521439e-03, ...,\n",
       "        -9.7661139e-04, -2.3199916e-03, -1.7621771e-03],\n",
       "       [-1.2133375e-03, -2.0367578e-03, -1.8232554e-03, ...,\n",
       "        -7.5757684e-04, -1.0999202e-03, -2.6829913e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWcFwPwLSo05",
    "outputId": "1cb97dd2-e2ff-4b34-8772-b12136f0d18c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'лаком я в мысли простой утвердился с годами семья это тайна покрытая браком <end> <start> из некоего жизненного круга нам выйти с неких пор не удаётся поэтому случайная подруга нечаянная влага из колодца <end> <start> ведём ли мы беседы грустные'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'кормил гусь национальный прибавили каждую утоленья свежих знавал девка антисемит цинизм тупик граница нести рожи дремлю вытворит суйся работящая поединке переврет стремились местах цветут копать жду глух свистнул глажу норы хохочет небосвода фактур веков кутерьма кошмары вляпывался кишении стайку сядем'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\" \".join(idx2token[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\" \".join(idx2token[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HrXTACTdzY-",
    "outputId": "5ce15c7d-c153-4901-cb6e-f694b819270c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 40, 19137)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       9.859294\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### Configure checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "tINIEZEzLH1C"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./training_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q71A8AWiOMa7",
    "outputId": "aa9ce27d-0942-43e0-c3af-a7f67f82c0ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access './training_checkpoints': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls ./training_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emFxS7TzdMx6",
    "outputId": "be19b201-9473-43cd-a06b-32b161f65ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gariki.txt  gdrive  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6fWTriUZP-n",
    "outputId": "32044afd-f022-431d-dac8-3ca33171e31f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto',\n",
    "    period=5,\n",
    "    #save_freq=88*5,\n",
    "    save_weights_only=True)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "early_stop = EarlyStopping(monitor='loss',\n",
    "                                     min_delta=0.003,\n",
    "                                     patience=1,\n",
    "                                     verbose=1,\n",
    "                                     mode='auto',\n",
    "                                     baseline=None,\n",
    "                                     restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        factor=0.1,\n",
    "                                        patience=0,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        min_delta=0.001,\n",
    "                                        cooldown=0,\n",
    "                                        min_lr=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### Execute the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остановил обучение когда исчезла надежда на хэппи энд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Os5AikoeWxAG",
    "outputId": "fc341371-8da1-461a-daec-1f352b2ffe0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 52s 2s/step - loss: 8.7277 - accuracy: 0.0812\n",
      "26/26 [==============================] - 52s 2s/step - loss: 7.6075 - accuracy: 0.1186\n",
      "26/26 [==============================] - 51s 2s/step - loss: 7.0290 - accuracy: 0.1336\n",
      "26/26 [==============================] - 51s 2s/step - loss: 6.2160 - accuracy: 0.1452\n",
      "26/26 [==============================] - ETA: 0s - loss: 4.9697 - accuracy: 0.1897\n",
      "Epoch 1: loss improved from inf to 4.96968, saving model to ./training_checkpoints/ckpt_1\n",
      "26/26 [==============================] - 73s 3s/step - loss: 4.9697 - accuracy: 0.1897\n",
      "26/26 [==============================] - 51s 2s/step - loss: 3.3722 - accuracy: 0.3826\n",
      "26/26 [==============================] - 49s 2s/step - loss: 2.2210 - accuracy: 0.5449\n",
      "26/26 [==============================] - 52s 2s/step - loss: 1.4874 - accuracy: 0.6731\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.9659 - accuracy: 0.7919\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.8818\n",
      "Epoch 1: loss improved from 4.96968 to 0.59799, saving model to ./training_checkpoints/ckpt_1\n",
      "26/26 [==============================] - 71s 3s/step - loss: 0.5980 - accuracy: 0.8818\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.3594 - accuracy: 0.9373\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.2322 - accuracy: 0.9597\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.1639 - accuracy: 0.9707\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.1261 - accuracy: 0.9779\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9828\n",
      "Epoch 1: loss improved from 0.59799 to 0.09964, saving model to ./training_checkpoints/ckpt_1\n",
      "26/26 [==============================] - 71s 3s/step - loss: 0.0996 - accuracy: 0.9828\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0828 - accuracy: 0.9859\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.0752 - accuracy: 0.9873\n",
      "26/26 [==============================] - 52s 2s/step - loss: 0.0701 - accuracy: 0.9880\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0663 - accuracy: 0.9880\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9881\n",
      "Epoch 1: loss improved from 0.09964 to 0.06424, saving model to ./training_checkpoints/ckpt_1\n",
      "26/26 [==============================] - 71s 3s/step - loss: 0.0642 - accuracy: 0.9881\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0624 - accuracy: 0.9883\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0616 - accuracy: 0.9880\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0592 - accuracy: 0.9883\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0588 - accuracy: 0.9882\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9877\n",
      "Epoch 1: loss improved from 0.06424 to 0.05911, saving model to ./training_checkpoints/ckpt_1\n",
      "26/26 [==============================] - 71s 3s/step - loss: 0.0591 - accuracy: 0.9877\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0601 - accuracy: 0.9879\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0592 - accuracy: 0.9877\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.0604 - accuracy: 0.9876\n",
      "26/26 [==============================] - 52s 2s/step - loss: 0.0596 - accuracy: 0.9876\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9870\n",
      "Epoch 1: loss did not improve from 0.05911\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0645 - accuracy: 0.9870\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0648 - accuracy: 0.9869\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0664 - accuracy: 0.9867\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0674 - accuracy: 0.9864\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.0665 - accuracy: 0.9862\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9854\n",
      "Epoch 1: loss did not improve from 0.05911\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.0750 - accuracy: 0.9854\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.0855 - accuracy: 0.9840\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.0947 - accuracy: 0.9824\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.1177 - accuracy: 0.9787\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.1509 - accuracy: 0.9730\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.9626\n",
      "Epoch 1: loss did not improve from 0.05911\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.1979 - accuracy: 0.9626\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.2902 - accuracy: 0.9400\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.4126 - accuracy: 0.9075\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.5074 - accuracy: 0.8825\n",
      "21/26 [=======================>......] - ETA: 9s - loss: 0.5016 - accuracy: 0.8808 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b5b31c224ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    model.fit(dataset, epochs=1, callbacks=[checkpoint_callback])\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK-hmKjYVoll"
   },
   "outputs": [],
   "source": [
    "#history = model.fit(dataset, \n",
    "#                    epochs=EPOCHS,  \n",
    "#                    callbacks=[checkpoint_callback, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "zk2WJ2-XjkGz",
    "outputId": "d44c3bab-245a-4866-fdb6-05554585edf6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./training_checkpoints/ckpt_1'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "U6ufpr8jcTUB",
    "outputId": "772fc619-dc83-49fd-bc6f-e2be18c953c4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./training_checkpoints'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71xa6jnYVrAN",
    "outputId": "2018bb08-6b5f-4964-d3ea-0a941db9b732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 2048)        39192576  \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, None, 4096)        75522048  \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, None, 4096)        100687872 \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, None, 4096)        100687872 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, 19137)       78404289  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 394,494,657\n",
      "Trainable params: 394,494,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, temperature, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 70\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [token2idx[s] for s in start_string.lower().split()]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = temperature # для понятности\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2token[predicted_id])\n",
    "\n",
    "    return (start_string + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktovv0RFhrkn",
    "outputId": "99f7c807-20c9-48f6-85cf-a21176d6c9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> Жизнь не внемлю лёгкого поведения есть закон рива ударит бы варяг питает игре в этой купле и я вперед талии чем еврей кто знает каждый забытое в жизни театральность <start> всё что прозрачный наживлённый этим любой способа жизни театральность <start> незря <start> поскольку денежный расти по счёту итога на белом а если взглянуть общения <end> <start> доволен я знаю что к вам делясь где то словно беда во рту рассветом нельзя\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, 0.7, start_string=u\"<start> Жизнь \")\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wqVniuFpofL",
    "outputId": "500f9614-f18f-45fe-a565-c958f222e4ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjuhCdppiVqy",
    "outputId": "468e0864-a636-4217-a756-3746f33b2c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> Жизнь не влился я не внемлю талии чем еврей кто знает каждый разум <end> <start> не на что будущее монахов и на белом мир на белом меня простишь весь слышны обычно весь дрязг этом нельзя и говорю что хочется при этом нельзя и на белом меня как зонтом и назад и на мне подкатит и тем еврею меж жизни театральность омерзения еврейского искусства себя хотящие течет шеи всего моя стонет и\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, 0.5, start_string=u\"<start> Жизнь \")\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5gwNpsh9Wkt",
    "outputId": "3e60295a-e398-480e-e24b-577ace44d3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> Жизнь не судьба моя стонет и на белом меня простишь весь слышны обычно весь слышны обычно весь слышны обычно весь слышны обычно весь дрязг этом нельзя и безмерно знает каждый забытое итога на хер чтоб в этой купле и что мне подкатит и дикое множество отличен лучшей сквозь стены <start> я не воспеты к вам делясь где то совал жизни театральность <start> я не влился я на белом мир на белом\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, 0.3, start_string=u\"<start> Жизнь \")\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4p3AIiW9WqT",
    "outputId": "220d4c80-131c-4498-f419-f930a0b94311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> Жизнь не судьба моя стонет и на белом а рот враг <end> <start> я не воспеты по разному мне подкатит и на белом а ебутся <end> <start> я не воспеты к ебене ясновидца я не находят верша так ли россию в себе по разному у каждого жалею во мне подкатит и на белом а я в этой купле и я в этой купле и суками вокруг пламень я не находят верша\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, 0.2, start_string=u\"<start> Жизнь \")\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZJvcELs-Hpn"
   },
   "source": [
    "Вывод: чем меньше температура тем больше матов :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHRJp5EJ9Wu2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation_Gariki_token.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
